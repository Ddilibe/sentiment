{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e7a61e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./env/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./env/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./env/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./env/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install requests\n",
    "# !pip install beautifulsoup4\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeebfb3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d28cad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import requests\n",
    "import string\n",
    "import pdb\n",
    "import io\n",
    "import os\n",
    "\n",
    "os.mkdir('Amazon/')\n",
    "base_repository = \"Amazon/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6479ee5a",
   "metadata": {},
   "source": [
    "## Retriving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7af86d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(url):\n",
    "  url = url.split('/')\n",
    "  url = url[len(url)-1].strip()\n",
    "  return url.translate(str.maketrans(\" \", \" \", string.punctuation))\n",
    "\n",
    "def save_file(url, file_name):\n",
    "  data, buf = requests.get(url), io.BytesIO()\n",
    "  with zipfile.ZipFile(f\"{base_repository}{file_name}.zip\", \"w\") as file:\n",
    "    jsonl = '.'.join([file_name.split('json')[0], 'jsonl'])\n",
    "    file.writestr(jsonl, data.content)\n",
    "\n",
    "def retrieve_list_of_url():\n",
    "  website = requests.get('https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023')\n",
    "  if website.status_code == 200:\n",
    "    soup = BeautifulSoup(website.text, 'html.parser')\n",
    "\n",
    "    def has_class_but_no_id(tag):\n",
    "      return tag.has_attr('rel') and tag.has_attr('download') and tag.has_attr('href')\n",
    "    a_links = soup.findAll(has_class_but_no_id)\n",
    "    return [a.get('href') for a in a_links]\n",
    "  else:\n",
    "    print(\"Generating Url Failed\")\n",
    "    return []\n",
    "\n",
    "def download_data_and_store():\n",
    "  org_data = pd.DataFrame({}, index=['rating', 'title', 'text', 'asin', 'parent_asin', 'user_id', 'timestamp', 'verified_purchase', 'helpful_vote'])\n",
    "  for i in retrieve_list_of_url():\n",
    "    file_name = get_file_name(i)\n",
    "    org_name = f\"{base_repository}{file_name}\"\n",
    "    save_file(i, file_name)\n",
    "    with zipfile.ZipFile(f\"{org_name}.zip\", 'r') as file:\n",
    "      file.extractall(org_name)\n",
    "    # os.remove(f\"{org_name}.zip\")\n",
    "    jsonl = '.'.join([file_name.split('json')[0], 'jsonl'])\n",
    "    data = pd.read_json(f\"{org_name}{jsonl}\", lines=True)\n",
    "    org_data.join(data)\n",
    "  return org_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4330bad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data = download_data_and_store()\n",
    "# data = pd.read_json(f\"Amazon/AllBrautyjsonlgz/AllBeauty.jsonl\", lines=True)\n",
    "os.getcwd()\n",
    "with zipfile.ZipFile(f\"Amazon/AllBeautyjsonlgz.zip\", 'r') as zip_file:\n",
    "  first_file = zip_file.namelist()[0]\n",
    "  with zip_file.open(first_file, 'r') as file:\n",
    "      print(file.read())\n",
    "#     content = file.read()\n",
    "#     content = content.decode('utf-8')\n",
    "#     print(type(content[5]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
